{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0007aab5-efdd-439e-bc3e-154049337313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text2paragraphs(filename, min_size=1):\n",
    "    \"\"\" A text contained in the file 'filename' will be read \n",
    "    and chopped into paragraphs.\n",
    "    Paragraphs with a string length less than min_size will be ignored.\n",
    "    A list of paragraph strings will be returned\"\"\"\n",
    "    \n",
    "    txt = open(filename).read()\n",
    "    paragraphs = [para for para in txt.split(\"\\n\\n\") if len(para) > min_size]\n",
    "    return paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281334d8-f51d-4429-9641-995e95598740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the position of lables is very important\n",
    "# it corresponds to a novel by that author within \"files\"\n",
    "# the position of the author is also relevant, as it will correspond to metrics\n",
    "# i.e. Samuel Butler's metrics are always returned in position 1\n",
    "labels = ['Virginia Woolf', 'Samuel Butler', 'Herman Melville', \n",
    "          'David Herbert Lawrence', 'Daniel Defoe', 'James Joyce']\n",
    "\n",
    "\n",
    "# names of books we have to train our machine model\n",
    "files = ['night_and_day_virginia_woolf.txt', 'the_way_of_all_flash_butler.txt',\n",
    "         'moby_dick_melville.txt', 'sons_and_lovers_lawrence.txt',\n",
    "         'robinson_crusoe_defoe.txt', 'james_joyce_ulysses.txt']\n",
    "\n",
    "# location of our books\n",
    "path = \"/home/student/mycode/natural/books/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097210ed-50dd-46a6-ac25-503be7ce473a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "targets = []\n",
    "counter = 0\n",
    "\n",
    "# loop across all files we have downloaded\n",
    "for fname in files:\n",
    "    paras = text2paragraphs(path + fname, min_size=150) # return a book with paragraphs over 150 chars in a list\n",
    "    data.extend(paras)\n",
    "    targets += [counter] * len(paras)\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75120d4a-a29a-4a94-8e3e-fa09b4c1830f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell is useless, because train_test_split will do the shuffling!\n",
    "\n",
    "import random\n",
    "\n",
    "data_targets = list(zip(data, targets))\n",
    "# splay (data_targets)\n",
    "# create random permutation on list:\n",
    "data_targets = random.sample(data_targets, len(data_targets))\n",
    "\n",
    "data, targets = list(zip(*data_targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "260f3797-d759-4ea9-9999-add5879bba92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "res = train_test_split(data, targets, \n",
    "                       train_size=0.8,\n",
    "                       test_size=0.2,\n",
    "                       random_state=42)\n",
    "train_data, test_data, train_targets, test_targets = res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de94bd9b-dfce-4d40-85ac-50fd2baa025b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.9183451279259662\n",
      "F1-score:  0.9138997235426528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectors = vectorizer.fit_transform(train_data)\n",
    "\n",
    "# creating a classifier\n",
    "classifier = MultinomialNB(alpha=.01)\n",
    "classifier.fit(vectors, train_targets)\n",
    "\n",
    "vectors_test = vectorizer.transform(test_data)\n",
    "\n",
    "predictions = classifier.predict(vectors_test)\n",
    "accuracy_score = metrics.accuracy_score(test_targets, \n",
    "                                        predictions)\n",
    "f1_score = metrics.f1_score(test_targets, \n",
    "                            predictions, \n",
    "                            average='macro')\n",
    "\n",
    "print(\"accuracy score: \", accuracy_score)\n",
    "print(\"F1-score: \", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74ccd38a-7029-492c-b7ae-d7820649d73f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 0 5 0 0 5 0 2 5 0 0 0 0 0 0 0 0 1 1 1 0 0 5 1 5 0 0 1 0 0 0 5 0 2 3 0\n",
      " 2 2 3 0 0 3 5 0 3 0 0 0 0 0 0 2 5 2 0 0 0 0 1 0 0 5 0 0 0 0 0 0 0 5 2 0 0\n",
      " 0 0 1 0 0 2 2 5 0 2 2 0 5 0 0 5 0 0 0 0 0 5 0 0 1 0 0 3 5 5 5 5 5 5 5 0 1\n",
      " 0 0 0 0 0 0 1 3 0 0 0 2 0 1 2 2 2 5 5 0 2 0 5 5 0 0 5 1 1 1 0 0 0 5 0 0 0\n",
      " 0 0 5 1 0 0 5 1 1 0 1 0 0 0 0 0 0 5 0 1 5 0 0 0 5 5 5 0 2 0 0 0 0 0 0 0 0\n",
      " 2 0 0 0 0 0 1 0 0 0 3 0 0 0 0 0 0 0 5 0 0 0 0 5 5 5 2 0 5 0 2 3 0 0 0 5 0\n",
      " 0 5 2 0 0 0 0 0 3 0 0 0 0 2 0 0 5 3 5 1 0 1 5 5 0 0 5 0 1 1 1 0 0 0 0 1 3\n",
      " 1 1 0 5 0 5 5 2 0 0 0 0 5 0 2 2 0 5 0 0 0 0 0 0 3 0 4 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 2 5 5 0 5 0 0 3 3 0 5 3 0 0 0 0 0 1 3 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 5\n",
      " 0 3 5 0 5 5 0 0 1 1 1 0 0 0 0 2 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0\n",
      " 1 1 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0]\n",
      "accuracy score:  0.6275\n",
      "precision score:  0.6275\n",
      "F1-score:  0.12852022529441884\n"
     ]
    }
   ],
   "source": [
    "# we want to use paragraphs from this 2nd Virginia Wolf \n",
    "paras = text2paragraphs(path + \"the_voyage_out_virginia_woolf.txt\", min_size=250)\n",
    "\n",
    "# start on paragraph 100 and go to paragraph 500\n",
    "first_para, last_para = 100, 500\n",
    "vectors_test = vectorizer.transform(paras[first_para: last_para]) # pass a list of strings that will be used to make predictions against\n",
    "#vectors_test = vectorizer.transform([\"To be or not to be\"])\n",
    "\n",
    "predictions = classifier.predict(vectors_test) # make our predictions\n",
    "print(predictions)\n",
    "targets = [0] * (last_para - first_para)\n",
    "accuracy_score = metrics.accuracy_score(targets, \n",
    "                                        predictions)\n",
    "precision_score = metrics.precision_score(targets, \n",
    "                                          predictions, \n",
    "                                          average='macro')\n",
    "\n",
    "f1_score = metrics.f1_score(targets, \n",
    "                            predictions, \n",
    "                            average='macro')\n",
    "\n",
    "print(\"accuracy score: \", accuracy_score)\n",
    "print(\"precision score: \", accuracy_score)\n",
    "print(\"F1-score: \", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a185e1-57d8-4ac2-91bd-0c58d662f50d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.28958409e-006 5.41514900e-008 2.74244416e-008 1.12368554e-010\n",
      "  2.63112149e-014 9.99998629e-001]\n",
      " [1.00000000e+000 6.12169406e-011 6.52293689e-013 2.07262711e-016\n",
      "  1.37017266e-025 9.09129406e-012]\n",
      " [9.99929690e-001 7.66152856e-014 2.52784354e-016 5.26982841e-012\n",
      "  4.41437976e-028 7.03096848e-005]\n",
      " ...\n",
      " [9.99999996e-001 3.55281162e-009 4.46287208e-054 1.94913095e-027\n",
      "  1.24433910e-051 3.85868741e-043]\n",
      " [9.90287105e-001 1.14141860e-019 7.11458544e-023 6.14294774e-030\n",
      "  1.44917768e-061 9.71289548e-003]\n",
      " [1.00000000e+000 6.56852768e-066 6.20125050e-087 2.92990215e-102\n",
      "  1.37836618e-134 1.70523802e-070]]\n"
     ]
    }
   ],
   "source": [
    "# perform a probability test\n",
    "predictions = classifier.predict_proba(vectors_test)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b86f9103-c737-4bed-9ab7-559c73a9d242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.28958409e-06 5.41514900e-08 2.74244416e-08 1.12368554e-10\n",
      " 2.63112149e-14 9.99998629e-01] \"That's the painful thing about pets,\" said Mr. Dalloway; \"they die. The\n",
      "first sorrow I can remember was for the death of a dormouse. I regret to\n",
      "say that I sat upon it. Still, that didn't make one any the less sorry.\n",
      "Here lies the duck that Samuel Johnson sat on, eh? I was big for my\n",
      "age.\"\n",
      "[1.00000000e+00 6.12169406e-11 6.52293689e-13 2.07262711e-16\n",
      " 1.37017266e-25 9.09129406e-12] \"Please tell me--everything.\" That was what she wanted to say. He had\n",
      "drawn apart one little chink and showed astonishing treasures. It seemed\n",
      "to her incredible that a man like that should be willing to talk to her.\n",
      "He had sisters and pets, and once lived in the country. She stirred her\n",
      "tea round and round; the bubbles which swam and clustered in the cup\n",
      "seemed to her like the union of their minds.\n",
      "[9.99929690e-01 7.66152856e-14 2.52784354e-16 5.26982841e-12\n",
      " 4.41437976e-28 7.03096848e-05] The talk meanwhile raced past her, and when Richard suddenly stated in a\n",
      "jocular tone of voice, \"I'm sure Miss Vinrace, now, has secret leanings\n",
      "towards Catholicism,\" she had no idea what to answer, and Helen could\n",
      "not help laughing at the start she gave.\n",
      "[1.13947746e-05 7.06219365e-10 1.69958019e-14 1.49210856e-05\n",
      " 2.95675106e-26 9.99973683e-01] However, breakfast was over and Mrs. Dalloway was rising. \"I always\n",
      "think religion's like collecting beetles,\" she said, summing up the\n",
      "discussion as she went up the stairs with Helen. \"One person has a\n",
      "passion for black beetles; another hasn't; it's no good arguing about\n",
      "it. What's _your_ black beetle now?\"\n",
      "[1.00000000e+00 1.61823803e-58 6.47929235e-55 1.05796346e-37\n",
      " 7.52669284e-98 2.97325341e-38] It was as though a blue shadow had fallen across a pool. Their eyes\n",
      "became deeper, and their voices more cordial. Instead of joining them\n",
      "as they began to pace the deck, Rachel was indignant with the prosperous\n",
      "matrons, who made her feel outside their world and motherless, and\n",
      "turning back, she left them abruptly. She slammed the door of her room,\n",
      "and pulled out her music. It was all old music--Bach and Beethoven,\n",
      "Mozart and Purcell--the pages yellow, the engraving rough to the finger.\n",
      "In three minutes she was deep in a very difficult, very classical fugue\n",
      "in A, and over her face came a queer remote impersonal expression of\n",
      "complete absorption and anxious satisfaction. Now she stumbled; now she\n",
      "faltered and had to play the same bar twice over; but an invisible\n",
      "line seemed to string the notes together, from which rose a shape,\n",
      "a building. She was so far absorbed in this work, for it was really\n",
      "difficult to find how all these sounds should stand together, and drew\n",
      "upon the whole of her faculties, that she never heard a knock at the\n",
      "door. It was burst impulsively open, and Mrs. Dalloway stood in the room\n",
      "leaving the door open, so that a strip of the white deck and of the blue\n",
      "sea appeared through the opening. The shape of the Bach fugue crashed to\n",
      "the ground.\n",
      "[6.78118273e-01 2.19360959e-02 2.69704215e-07 1.13304926e-04\n",
      " 3.93427274e-23 2.99832056e-01] \"He wrote awfully well, didn't he?\" said Clarissa; \"--if one likes\n",
      "that kind of thing--finished his sentences and all that. _Wuthering_\n",
      "_Heights_! Ah--that's more in my line. I really couldn't exist without\n",
      "the Brontes! Don't you love them? Still, on the whole, I'd rather live\n",
      "without them than without Jane Austen.\"\n",
      "[2.28402777e-06 2.35034673e-19 2.52540989e-06 2.34258171e-16\n",
      " 2.25223499e-35 9.99995191e-01] How divine!--and yet what nonsense!\" She looked lightly round the room.\n",
      "\"I always think it's _living_, not dying, that counts. I really respect\n",
      "some snuffy old stockbroker who's gone on adding up column after column\n",
      "all his days, and trotting back to his villa at Brixton with some old\n",
      "pug dog he worships, and a dreary little wife sitting at the end of the\n",
      "table, and going off to Margate for a fortnight--I assure you I know\n",
      "heaps like that--well, they seem to me _really_ nobler than poets whom\n",
      "every one worships, just because they're geniuses and die young. But I\n",
      "don't expect _you_ to agree with me!\"\n",
      "[9.62114628e-01 3.78763456e-02 3.74473041e-13 7.83499611e-12\n",
      " 3.00272837e-17 9.02623993e-06] \"When you're my age you'll see that the world is _crammed_ with\n",
      "delightful things. I think young people make such a mistake about\n",
      "that--not letting themselves be happy. I sometimes think that happiness\n",
      "is the only thing that counts. I don't know you well enough to say, but\n",
      "I should guess you might be a little inclined to--when one's young and\n",
      "attractive--I'm going to say it!--_every_thing's at one's feet.\" She\n",
      "glanced round as much as to say, \"not only a few stuffy books and Bach.\"\n",
      "[6.68507506e-09 1.49510217e-19 9.99552334e-01 7.18179438e-11\n",
      " 4.42768155e-04 4.89103036e-06] The shores of Portugal were beginning to lose their substance; but\n",
      "the land was still the land, though at a great distance. They could\n",
      "distinguish the little towns that were sprinkled in the folds of the\n",
      "hills, and the smoke rising faintly. The towns appeared to be very small\n",
      "in comparison with the great purple mountains behind them.\n",
      "[1.76508850e-04 5.28976099e-13 1.34286721e-01 7.54937878e-12\n",
      " 7.72857637e-18 8.65536770e-01] Rachel followed her eyes and found that they rested for a second, on the\n",
      "robust figure of Richard Dalloway, who was engaged in striking a match\n",
      "on the sole of his boot; while Willoughby expounded something, which\n",
      "seemed to be of great interest to them both.\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(predictions[i], paras[i+first_para])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f28b351-efa8-46cd-88c9-29ad28c08e80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
