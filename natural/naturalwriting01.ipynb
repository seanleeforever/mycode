{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0007aab5-efdd-439e-bc3e-154049337313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text2paragraphs(filename, min_size=1):\n",
    "    \"\"\" A text contained in the file 'filename' will be read \n",
    "    and chopped into paragraphs.\n",
    "    Paragraphs with a string length less than min_size will be ignored.\n",
    "    A list of paragraph strings will be returned\"\"\"\n",
    "    \n",
    "    txt = open(filename).read()\n",
    "    paragraphs = [para for para in txt.split(\"\\n\\n\") if len(para) > min_size]\n",
    "    return paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281334d8-f51d-4429-9641-995e95598740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the position of lables is very important\n",
    "# it corresponds to a novel by that author within \"files\"\n",
    "# the position of the author is also relevant, as it will correspond to metrics\n",
    "# i.e. Samuel Butler's metrics are always returned in position 1\n",
    "labels = ['Virginia Woolf', 'Samuel Butler', 'Herman Melville', \n",
    "          'David Herbert Lawrence', 'Daniel Defoe', 'James Joyce']\n",
    "\n",
    "\n",
    "# names of books we have to train our machine model\n",
    "files = ['night_and_day_virginia_woolf.txt', 'the_way_of_all_flash_butler.txt',\n",
    "         'moby_dick_melville.txt', 'sons_and_lovers_lawrence.txt',\n",
    "         'robinson_crusoe_defoe.txt', 'james_joyce_ulysses.txt']\n",
    "\n",
    "# location of our books\n",
    "path = \"/home/student/mycode/natural/books/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097210ed-50dd-46a6-ac25-503be7ce473a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "targets = []\n",
    "counter = 0\n",
    "\n",
    "# loop across all files we have downloaded\n",
    "for fname in files:\n",
    "    paras = text2paragraphs(path + fname, min_size=150) # return a book with paragraphs over 150 chars in a list\n",
    "    data.extend(paras)\n",
    "    targets += [counter] * len(paras)\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75120d4a-a29a-4a94-8e3e-fa09b4c1830f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell is useless, because train_test_split will do the shuffling!\n",
    "\n",
    "import random\n",
    "\n",
    "data_targets = list(zip(data, targets))\n",
    "# splay (data_targets)\n",
    "# create random permutation on list:\n",
    "data_targets = random.sample(data_targets, len(data_targets))\n",
    "\n",
    "data, targets = list(zip(*data_targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "260f3797-d759-4ea9-9999-add5879bba92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "res = train_test_split(data, targets, \n",
    "                       train_size=0.8,\n",
    "                       test_size=0.2,\n",
    "                       random_state=42)\n",
    "train_data, test_data, train_targets, test_targets = res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de94bd9b-dfce-4d40-85ac-50fd2baa025b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.9183451279259662\n",
      "F1-score:  0.9138997235426528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectors = vectorizer.fit_transform(train_data)\n",
    "\n",
    "# creating a classifier\n",
    "classifier = MultinomialNB(alpha=.01)\n",
    "classifier.fit(vectors, train_targets)\n",
    "\n",
    "vectors_test = vectorizer.transform(test_data)\n",
    "\n",
    "predictions = classifier.predict(vectors_test)\n",
    "accuracy_score = metrics.accuracy_score(test_targets, \n",
    "                                        predictions)\n",
    "f1_score = metrics.f1_score(test_targets, \n",
    "                            predictions, \n",
    "                            average='macro')\n",
    "\n",
    "print(\"accuracy score: \", accuracy_score)\n",
    "print(\"F1-score: \", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74ccd38a-7029-492c-b7ae-d7820649d73f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 0 5 0 0 5 0 2 5 0 0 0 0 0 0 0 0 1 1 1 0 0 5 1 5 0 0 1 0 0 0 5 0 2 3 0\n",
      " 2 2 3 0 0 3 5 0 3 0 0 0 0 0 0 2 5 2 0 0 0 0 1 0 0 5 0 0 0 0 0 0 0 5 2 0 0\n",
      " 0 0 1 0 0 2 2 5 0 2 2 0 5 0 0 5 0 0 0 0 0 5 0 0 1 0 0 3 5 5 5 5 5 5 5 0 1\n",
      " 0 0 0 0 0 0 1 3 0 0 0 2 0 1 2 2 2 5 5 0 2 0 5 5 0 0 5 1 1 1 0 0 0 5 0 0 0\n",
      " 0 0 5 1 0 0 5 1 1 0 1 0 0 0 0 0 0 5 0 1 5 0 0 0 5 5 5 0 2 0 0 0 0 0 0 0 0\n",
      " 2 0 0 0 0 0 1 0 0 0 3 0 0 0 0 0 0 0 5 0 0 0 0 5 5 5 2 0 5 0 2 3 0 0 0 5 0\n",
      " 0 5 2 0 0 0 0 0 3 0 0 0 0 2 0 0 5 3 5 1 0 1 5 5 0 0 5 0 1 1 1 0 0 0 0 1 3\n",
      " 1 1 0 5 0 5 5 2 0 0 0 0 5 0 2 2 0 5 0 0 0 0 0 0 3 0 4 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 2 5 5 0 5 0 0 3 3 0 5 3 0 0 0 0 0 1 3 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 5\n",
      " 0 3 5 0 5 5 0 0 1 1 1 0 0 0 0 2 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0\n",
      " 1 1 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0]\n",
      "accuracy score:  0.6275\n",
      "precision score:  0.6275\n",
      "F1-score:  0.12852022529441884\n"
     ]
    }
   ],
   "source": [
    "# we want to use paragraphs from this 2nd Virginia Wolf \n",
    "paras = text2paragraphs(path + \"the_voyage_out_virginia_woolf.txt\", min_size=250)\n",
    "\n",
    "# start on paragraph 100 and go to paragraph 500\n",
    "first_para, last_para = 100, 500\n",
    "vectors_test = vectorizer.transform(paras[first_para: last_para]) # pass a list of strings that will be used to make predictions against\n",
    "#vectors_test = vectorizer.transform([\"To be or not to be\"])\n",
    "\n",
    "predictions = classifier.predict(vectors_test) # make our predictions\n",
    "print(predictions)\n",
    "targets = [0] * (last_para - first_para)\n",
    "accuracy_score = metrics.accuracy_score(targets, \n",
    "                                        predictions)\n",
    "precision_score = metrics.precision_score(targets, \n",
    "                                          predictions, \n",
    "                                          average='macro')\n",
    "\n",
    "f1_score = metrics.f1_score(targets, \n",
    "                            predictions, \n",
    "                            average='macro')\n",
    "\n",
    "print(\"accuracy score: \", accuracy_score)\n",
    "print(\"precision score: \", accuracy_score)\n",
    "print(\"F1-score: \", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a185e1-57d8-4ac2-91bd-0c58d662f50d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.28958409e-006 5.41514900e-008 2.74244416e-008 1.12368554e-010\n",
      "  2.63112149e-014 9.99998629e-001]\n",
      " [1.00000000e+000 6.12169406e-011 6.52293689e-013 2.07262711e-016\n",
      "  1.37017266e-025 9.09129406e-012]\n",
      " [9.99929690e-001 7.66152856e-014 2.52784354e-016 5.26982841e-012\n",
      "  4.41437976e-028 7.03096848e-005]\n",
      " ...\n",
      " [9.99999996e-001 3.55281162e-009 4.46287208e-054 1.94913095e-027\n",
      "  1.24433910e-051 3.85868741e-043]\n",
      " [9.90287105e-001 1.14141860e-019 7.11458544e-023 6.14294774e-030\n",
      "  1.44917768e-061 9.71289548e-003]\n",
      " [1.00000000e+000 6.56852768e-066 6.20125050e-087 2.92990215e-102\n",
      "  1.37836618e-134 1.70523802e-070]]\n"
     ]
    }
   ],
   "source": [
    "# perform a probability test\n",
    "predictions = classifier.predict_proba(vectors_test)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f9103-c737-4bed-9ab7-559c73a9d242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
